{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carlos1729/DGL/blob/main/Link_Prediction_using_Graph_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HoElaRFn75Dh"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ic_DZxB75Dj"
      },
      "source": [
        "\n",
        "Link Prediction using Graph Neural Networks\n",
        "===========================================\n",
        "\n",
        "In the :doc:`introduction <1_introduction>`, you have already learned\n",
        "the basic workflow of using GNNs for node classification,\n",
        "i.e. predicting the category of a node in a graph. This tutorial will\n",
        "teach you how to train a GNN for link prediction, i.e. predicting the\n",
        "existence of an edge between two arbitrary nodes in a graph.\n",
        "\n",
        "By the end of this tutorial you will be able to\n",
        "\n",
        "-  Build a GNN-based link prediction model.\n",
        "-  Train and evaluate the model on a small DGL-provided dataset.\n",
        "\n",
        "(Time estimate: 28 minutes)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  dgl -f https://data.dgl.ai/wheels/cu116/repo.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8YL1Ol58KTc",
        "outputId": "1b32fdd4-497b-4f98-adec-1982db6d661a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/cu116/repo.html\n",
            "Collecting dgl\n",
            "  Downloading https://data.dgl.ai/wheels/cu116/dgl-1.1.2%2Bcu116-cp310-cp310-manylinux1_x86_64.whl (92.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.3)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.7.22)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.2+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R048l7rd8KGK",
        "outputId": "a2975532-d2b7-4554-eaa5-d3432f7f54e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
            "Collecting dglgo\n",
            "  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.9.0)\n",
            "Collecting isort>=5.10.1 (from dglgo)\n",
            "  Downloading isort-5.12.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autopep8>=1.6.0 (from dglgo)\n",
            "  Downloading autopep8-2.0.4-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpydoc>=1.1.0 (from dglgo)\n",
            "  Downloading numpydoc-1.6.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.10.13)\n",
            "Collecting ruamel.yaml>=0.17.20 (from dglgo)\n",
            "  Downloading ruamel.yaml-0.18.3-py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (6.0.1)\n",
            "Collecting ogb>=1.3.3 (from dglgo)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdkit-pypi (from dglgo)\n",
            "  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.2.2)\n",
            "Collecting pycodestyle>=2.10.0 (from autopep8>=1.6.0->dglgo)\n",
            "  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: sphinx>=5 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (5.0.2)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (0.9.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (4.66.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.0.7)\n",
            "Collecting outdated>=0.2.0 (from ogb>=1.3.3->dglgo)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (4.5.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.20->dglgo)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.2.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.0->dglgo) (8.1.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi->dglgo) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb>=1.3.3->dglgo)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2023.3.post1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.1.9)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.6)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.16.1)\n",
            "Requirement already satisfied: docutils<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (0.18.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.13.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7028 sha256=a42472e4f5fbad4809b8327e0cbd4317d8965a7c8b97396fe7f56b5772602689\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, ruamel.yaml.clib, rdkit-pypi, pycodestyle, isort, ruamel.yaml, outdated, autopep8, ogb, numpydoc, dglgo\n",
            "Successfully installed autopep8-2.0.4 dglgo-0.0.2 isort-5.12.0 littleutils-0.2.2 numpydoc-1.6.0 ogb-1.3.6 outdated-0.2.2 pycodestyle-2.11.1 rdkit-pypi-2022.9.5 ruamel.yaml-0.18.3 ruamel.yaml.clib-0.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCqmi9_M75Dl",
        "outputId": "9fda7718-c9f6-4f30-c87b-8be82f2cf8a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ],
      "source": [
        "import dgl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "import numpy as np\n",
        "import scipy.sparse as sp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJnJpqDt75Dm"
      },
      "source": [
        "Overview of Link Prediction with GNN\n",
        "------------------------------------\n",
        "\n",
        "Many applications such as social recommendation, item recommendation,\n",
        "knowledge graph completion, etc., can be formulated as link prediction,\n",
        "which predicts whether an edge exists between two particular nodes. This\n",
        "tutorial shows an example of predicting whether a citation relationship,\n",
        "either citing or being cited, between two papers exists in a citation\n",
        "network.\n",
        "\n",
        "This tutorial formulates the link prediction problem as a binary classification\n",
        "problem as follows:\n",
        "\n",
        "-  Treat the edges in the graph as *positive examples*.\n",
        "-  Sample a number of non-existent edges (i.e. node pairs with no edges\n",
        "   between them) as *negative* examples.\n",
        "-  Divide the positive examples and negative examples into a training\n",
        "   set and a test set.\n",
        "-  Evaluate the model with any binary classification metric such as Area\n",
        "   Under Curve (AUC).\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The practice comes from\n",
        "   `SEAL <https://papers.nips.cc/paper/2018/file/53f0d7c537d99b3824f0f99d62ea2428-Paper.pdf>`__,\n",
        "   although the model here does not use their idea of node labeling.</p></div>\n",
        "\n",
        "In some domains such as large-scale recommender systems or information\n",
        "retrieval, you may favor metrics that emphasize good performance of\n",
        "top-K predictions. In these cases you may want to consider other metrics\n",
        "such as mean average precision, and use other negative sampling methods,\n",
        "which are beyond the scope of this tutorial.\n",
        "\n",
        "Loading graph and features\n",
        "--------------------------\n",
        "\n",
        "Following the :doc:`introduction <1_introduction>`, this tutorial\n",
        "first loads the Cora dataset.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "104jOu7B75Dm",
        "outputId": "8753bb4d-cca7-442a-c5ed-4301e3e78de9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n",
            "Extracting file to /root/.dgl/cora_v2_d697a464\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done saving data into cached files.\n"
          ]
        }
      ],
      "source": [
        "import dgl.data\n",
        "\n",
        "dataset = dgl.data.CoraGraphDataset()\n",
        "g = dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sgBkTVN75Dn"
      },
      "source": [
        "Prepare training and testing sets\n",
        "---------------------------------\n",
        "\n",
        "This tutorial randomly picks 10% of the edges for positive examples in\n",
        "the test set, and leave the rest for the training set. It then samples\n",
        "the same number of edges for negative examples in both sets.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g.edges()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmRlNv9W9JO-",
        "outputId": "5f0ebad2-6de7-400a-8e67-ccd815752ddf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([   0,    0,    0,  ..., 2707, 2707, 2707]),\n",
              " tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split edge set for training and testing\n",
        "u, v = g.edges()\n",
        "\n",
        "eids = np.arange(g.number_of_edges())\n",
        "eids = np.random.permutation(eids)\n",
        "test_size = int(len(eids) * 0.1)\n",
        "train_size = g.number_of_edges() - test_size\n",
        "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
        "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]"
      ],
      "metadata": {
        "id": "oPKE4YCV-W9q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos_u, train_pos_v, train_pos_v.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkmUtYNG-Y8X",
        "outputId": "9f3122d7-762a-47c9-d797-bb7e8a49c4da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 336, 1358, 1219,  ...,  525, 1555, 1023]),\n",
              " tensor([1950, 1725,   45,  ...,  456, 2363, 1701]),\n",
              " torch.Size([9501]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pos_u, test_pos_v, test_pos_v.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9BgnMJJ-e-Y",
        "outputId": "7b9282cc-1b1f-46a3-b65e-413e268afd59"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2359, 1627,  111,  ..., 2444,  877, 1771]),\n",
              " tensor([1834, 1740, 1358,  ..., 2503, 1177,  306]),\n",
              " torch.Size([1055]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all negative edges and split them for training and testing\n",
        "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))"
      ],
      "metadata": {
        "id": "3TUifNIF--T5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj.size, adj.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHguPfTP_UGf",
        "outputId": "6ef82f02-6cc3-4f2d-c532-763e42580eea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10556, (2708, 2708))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(adj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQVt8mrI_IkF",
        "outputId": "fd897531-ae8b-4a77-b82a-9b00a3d9de47"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 633)\t1.0\n",
            "  (0, 1862)\t1.0\n",
            "  (0, 2582)\t1.0\n",
            "  (1, 2)\t1.0\n",
            "  (1, 652)\t1.0\n",
            "  (1, 654)\t1.0\n",
            "  (2, 1)\t1.0\n",
            "  (2, 1986)\t1.0\n",
            "  (2, 332)\t1.0\n",
            "  (2, 1666)\t1.0\n",
            "  (2, 1454)\t1.0\n",
            "  (3, 2544)\t1.0\n",
            "  (4, 2176)\t1.0\n",
            "  (4, 1016)\t1.0\n",
            "  (4, 1761)\t1.0\n",
            "  (4, 1256)\t1.0\n",
            "  (4, 2175)\t1.0\n",
            "  (5, 1629)\t1.0\n",
            "  (5, 2546)\t1.0\n",
            "  (5, 1659)\t1.0\n",
            "  (6, 1416)\t1.0\n",
            "  (6, 1602)\t1.0\n",
            "  (6, 1042)\t1.0\n",
            "  (6, 373)\t1.0\n",
            "  (7, 208)\t1.0\n",
            "  :\t:\n",
            "  (2694, 431)\t1.0\n",
            "  (2694, 2695)\t1.0\n",
            "  (2695, 431)\t1.0\n",
            "  (2695, 2694)\t1.0\n",
            "  (2696, 2615)\t1.0\n",
            "  (2697, 986)\t1.0\n",
            "  (2698, 1400)\t1.0\n",
            "  (2698, 1573)\t1.0\n",
            "  (2699, 2630)\t1.0\n",
            "  (2700, 1151)\t1.0\n",
            "  (2701, 44)\t1.0\n",
            "  (2701, 2624)\t1.0\n",
            "  (2702, 186)\t1.0\n",
            "  (2702, 1536)\t1.0\n",
            "  (2703, 1298)\t1.0\n",
            "  (2704, 641)\t1.0\n",
            "  (2705, 287)\t1.0\n",
            "  (2706, 165)\t1.0\n",
            "  (2706, 169)\t1.0\n",
            "  (2706, 1473)\t1.0\n",
            "  (2706, 2707)\t1.0\n",
            "  (2707, 165)\t1.0\n",
            "  (2707, 598)\t1.0\n",
            "  (2707, 1473)\t1.0\n",
            "  (2707, 2706)\t1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(adj.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hly1QIz8_Isr",
        "outputId": "3241f5df-09fc-4718-91f7-baac0f20880e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(adj.toarray()[1][652])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR4ZlVdY_Ivm",
        "outputId": "b886f640-ed51-44b6-ae14-d478e8bf5a3d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
        "adj_neg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-dhDoLr_Iy8",
        "outputId": "ab2327aa-ae0f-438d-f0bc-fcb498e81251"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 0., 0., ..., 1., 1., 1.],\n",
              "        [1., 0., 0., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., ..., 0., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 0., 0.],\n",
              "        [1., 1., 1., ..., 1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculates a matrix adj_neg which represents the negation of the adjacency matrix. It sets values to 0 where there are edges and avoids self-loops (diagonal entries)."
      ],
      "metadata": {
        "id": "NijXJyBLA5A4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neg_u, neg_v = np.where(adj_neg != 0)"
      ],
      "metadata": {
        "id": "RPD48GG1A3Ht"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neg_u,neg_v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c_O14uYBHR0",
        "outputId": "a4d701a4-a8c3-4364-b4b2-7f5ca1059ea0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([   0,    0,    0, ..., 2707, 2707, 2707]),\n",
              " array([   1,    2,    3, ..., 2703, 2704, 2705]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Kf_9BU5W75Dn"
      },
      "outputs": [],
      "source": [
        "neg_eids = np.random.choice(len(neg_u), g.number_of_edges())\n",
        "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
        "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_neg_u, test_neg_v, test_neg_v.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-F8ab3nBQqk",
        "outputId": "4515dded-1de7-4771-81f0-8e0b71e99b70"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 186,  977, 1679, ...,   51, 2367, 2386]),\n",
              " array([2002,  274, 2364, ..., 2706, 2122, 1633]),\n",
              " (1055,))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_neg_u, train_neg_v, train_neg_v.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1LPkhb6BUGQ",
        "outputId": "243eda81-ca5d-4064-a289-c11d4c5ad07f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1376, 2248, 2015, ...,  365,  334, 1915]),\n",
              " array([ 703, 1376,  617, ..., 1330, 2132,  663]),\n",
              " (9501,))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPwZ7k2w75Dn"
      },
      "source": [
        "When training, you will need to remove the edges in the test set from\n",
        "the original graph. You can do this via ``dgl.remove_edges``.\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``dgl.remove_edges`` works by creating a subgraph from the\n",
        "   original graph, resulting in a copy and therefore could be slow for\n",
        "   large graphs. If so, you could save the training and test graph to\n",
        "   disk, as you would do for preprocessing.</p></div>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "n_ly76jP75Dn"
      },
      "outputs": [],
      "source": [
        "train_g = dgl.remove_edges(g, eids[:test_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffWKgrWg75Do"
      },
      "source": [
        "Define a GraphSAGE model\n",
        "------------------------\n",
        "\n",
        "This tutorial builds a model consisting of two\n",
        "`GraphSAGE <https://arxiv.org/abs/1706.02216>`__ layers, each computes\n",
        "new node representations by averaging neighbor information. DGL provides\n",
        "``dgl.nn.SAGEConv`` that conveniently creates a GraphSAGE layer.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "o9k9Z9U575Do"
      },
      "outputs": [],
      "source": [
        "from dgl.nn import SAGEConv\n",
        "\n",
        "# ----------- 2. create model -------------- #\n",
        "# build a two-layer GraphSAGE model\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
        "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hXJ1CTQ75Do"
      },
      "source": [
        "The model then predicts the probability of existence of an edge by\n",
        "computing a score between the representations of both incident nodes\n",
        "with a function (e.g. an MLP or a dot product), which you will see in\n",
        "the next section.\n",
        "\n",
        "\\begin{align}\\hat{y}_{u\\sim v} = f(h_u, h_v)\\end{align}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEQqW4RN75Do"
      },
      "source": [
        "Positive graph, negative graph, and ``apply_edges``\n",
        "---------------------------------------------------\n",
        "\n",
        "In previous tutorials you have learned how to compute node\n",
        "representations with a GNN. However, link prediction requires you to\n",
        "compute representation of *pairs of nodes*.\n",
        "\n",
        "DGL recommends you to treat the pairs of nodes as another graph, since\n",
        "you can describe a pair of nodes with an edge. In link prediction, you\n",
        "will have a *positive graph* consisting of all the positive examples as\n",
        "edges, and a *negative graph* consisting of all the negative examples.\n",
        "The *positive graph* and the *negative graph* will contain the same set\n",
        "of nodes as the original graph.  This makes it easier to pass node\n",
        "features among multiple graphs for computation.  As you will see later,\n",
        "you can directly feed the node representations computed on the entire\n",
        "graph to the positive and the negative graphs for computing pair-wise\n",
        "scores.\n",
        "\n",
        "The following code constructs the positive graph and the negative graph\n",
        "for the training set and the test set respectively.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "f9KSKF1l75Dp"
      },
      "outputs": [],
      "source": [
        "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes())\n",
        "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
        "\n",
        "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
        "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos_g"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2B_iboaFDfm",
        "outputId": "b840c18b-11ca-455f-bcbf-845a49a4c0f0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes=2708, num_edges=9501,\n",
              "      ndata_schemes={}\n",
              "      edata_schemes={})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_neg_g"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4kBhtbXFDiT",
        "outputId": "0f695e58-8136-40cd-a437-fbbad86db28c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes=2708, num_edges=9501,\n",
              "      ndata_schemes={}\n",
              "      edata_schemes={})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pos_g"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EA1nERwFDlL",
        "outputId": "d156fa34-7ce1-48e7-e3da-982a51c44c73"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes=2708, num_edges=1055,\n",
              "      ndata_schemes={}\n",
              "      edata_schemes={})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_neg_g"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDY4dmlOFDoW",
        "outputId": "8918cb73-411a-4829-ec4b-079d9550538c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes=2708, num_edges=1055,\n",
              "      ndata_schemes={}\n",
              "      edata_schemes={})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuFD89Zw75Dp"
      },
      "source": [
        "The benefit of treating the pairs of nodes as a graph is that you can\n",
        "use the ``DGLGraph.apply_edges`` method, which conveniently computes new\n",
        "edge features based on the incident nodes’ features and the original\n",
        "edge features (if applicable).\n",
        "\n",
        "DGL provides a set of optimized builtin functions to compute new\n",
        "edge features based on the original node/edge features. For example,\n",
        "``dgl.function.u_dot_v`` computes a dot product of the incident nodes’\n",
        "representations for each edge.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "taqIbiU275Dp"
      },
      "outputs": [],
      "source": [
        "import dgl.function as fn\n",
        "\n",
        "class DotPredictor(nn.Module):\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():#This line creates a local scope for the graph g. Operations performed within this scope won't affect the original graph but will be applied in a temporary context.\n",
        "            g.ndata['h'] = h#It assigns the node features h to the nodes of the graph g with the key 'h'. This means that each node in the graph now has a feature called 'h'.\n",
        "            # Compute a new edge feature named 'score' by a dot-product between the\n",
        "            # source node feature 'h' and destination node feature 'h'.\n",
        "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
        "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
        "            return g.edata['score'][:, 0]\n",
        "\n",
        "\n",
        "#In summary, the DotPredictor class computes edge scores in a graph by calculating the dot product between the node features of the\n",
        "# source and destination nodes for each edge. The computed scores are stored as edge features and can be used for various graph-related tasks such as link prediction or graph classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgglZZw-75Dp"
      },
      "source": [
        "You can also write your own function if it is complex.\n",
        "For instance, the following module produces a scalar score on each edge\n",
        "by concatenating the incident nodes’ features and passing it to an MLP.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qeAcaabo75Dq"
      },
      "outputs": [],
      "source": [
        "class MLPPredictor(nn.Module):\n",
        "    def __init__(self, h_feats):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
        "        self.W2 = nn.Linear(h_feats, 1)\n",
        "\n",
        "    def apply_edges(self, edges):\n",
        "        \"\"\"\n",
        "        Computes a scalar score for each edge of the given graph.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        edges :\n",
        "            Has three members ``src``, ``dst`` and ``data``, each of\n",
        "            which is a dictionary representing the features of the\n",
        "            source nodes, the destination nodes, and the edges\n",
        "            themselves.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dict\n",
        "            A dictionary of new edge features.\n",
        "        \"\"\"\n",
        "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
        "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            g.apply_edges(self.apply_edges)\n",
        "            return g.edata['score']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qu_VD2775Dq"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The builtin functions are optimized for both speed and memory.\n",
        "   We recommend using builtin functions whenever possible.</p></div>\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>If you have read the :doc:`message passing\n",
        "   tutorial <3_message_passing>`, you will notice that the\n",
        "   argument ``apply_edges`` takes has exactly the same form as a message\n",
        "   function in ``update_all``.</p></div>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D1xtQ_F75Dq"
      },
      "source": [
        "Training loop\n",
        "-------------\n",
        "\n",
        "After you defined the node representation computation and the edge score\n",
        "computation, you can go ahead and define the overall model, loss\n",
        "function, and evaluation metric.\n",
        "\n",
        "The loss function is simply binary cross entropy loss.\n",
        "\n",
        "\\begin{align}\\mathcal{L} = -\\sum_{u\\sim v\\in \\mathcal{D}}\\left( y_{u\\sim v}\\log(\\hat{y}_{u\\sim v}) + (1-y_{u\\sim v})\\log(1-\\hat{y}_{u\\sim v})) \\right)\\end{align}\n",
        "\n",
        "The evaluation metric in this tutorial is AUC.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_g\n",
        "#train_g = dgl.remove_edges(g, eids[:test_size])itwas previously generated here the traing graph for entire datset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRC3JYLXIOSp",
        "outputId": "e57b68a1-6fe2-4baa-ed33-82ea0ff11709"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes=2708, num_edges=9501,\n",
              "      ndata_schemes={'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'label': Scheme(shape=(), dtype=torch.int64), 'feat': Scheme(shape=(1433,), dtype=torch.float32)}\n",
              "      edata_schemes={})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_g.ndata['feat']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AfqpmraIO4J",
        "outputId": "e38688e4-a19c-477a-ad3c-bcd10c1ad2c1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_g.ndata['feat'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE9m6wJPIO6w",
        "outputId": "e5502917-1a22-4581-cddb-5f8df1767535"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2708, 1433])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_g.ndata['feat'].shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoJJedgLIO9a",
        "outputId": "2dddbaaa-bdac-4b50-d5b3-8c7f43062596"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1433"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from dgl.nn import SAGEConv\n",
        "\n",
        "# # ----------- 2. create model -------------- #\n",
        "# # build a two-layer GraphSAGE model\n",
        "# class GraphSAGE(nn.Module):\n",
        "#     def __init__(self, in_feats, h_feats):\n",
        "#         super(GraphSAGE, self).__init__()\n",
        "#         self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
        "#         self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
        "\n",
        "#     def forward(self, g, in_feat):\n",
        "#         h = self.conv1(g, in_feat)\n",
        "#         h = F.relu(h)\n",
        "#         h = self.conv2(g, h)\n",
        "#         return h"
      ],
      "metadata": {
        "id": "pfaHrQ7RIPA0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphSAGE(train_g.ndata['feat'].shape[1], 16)"
      ],
      "metadata": {
        "id": "YiJycL1cJZg8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can replace DotPredictor with MLPPredictor.\n",
        "#pred = MLPPredictor(16)\n",
        "pred = DotPredictor()"
      ],
      "metadata": {
        "id": "P8n-IgBoJZkf"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "def compute_auc(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
        "    return roc_auc_score(labels, scores)"
      ],
      "metadata": {
        "id": "tTdhjI_RJkO4"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0LG-GWv75Dq"
      },
      "source": [
        "The training loop goes as follows:\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>This tutorial does not include evaluation on a validation\n",
        "   set. In practice you should save and evaluate the best model based on\n",
        "   performance on the validation set.</p></div>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjQv3Cmi75Dr",
        "outputId": "8cad3795-f5b4-4b84-f6df-ddeecb90077a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0, loss: 0.7002516984939575\n",
            "In epoch 5, loss: 0.6892386078834534\n",
            "In epoch 10, loss: 0.6658018231391907\n",
            "In epoch 15, loss: 0.601407527923584\n",
            "In epoch 20, loss: 0.5289682745933533\n",
            "In epoch 25, loss: 0.500198483467102\n",
            "In epoch 30, loss: 0.4677374064922333\n",
            "In epoch 35, loss: 0.4474698007106781\n",
            "In epoch 40, loss: 0.4211966097354889\n",
            "In epoch 45, loss: 0.3991188108921051\n",
            "In epoch 50, loss: 0.37885192036628723\n",
            "In epoch 55, loss: 0.3559190034866333\n",
            "In epoch 60, loss: 0.33320558071136475\n",
            "In epoch 65, loss: 0.3105471432209015\n",
            "In epoch 70, loss: 0.2873142957687378\n",
            "In epoch 75, loss: 0.26484575867652893\n",
            "In epoch 80, loss: 0.24197407066822052\n",
            "In epoch 85, loss: 0.2191516011953354\n",
            "In epoch 90, loss: 0.19638673961162567\n",
            "In epoch 95, loss: 0.17408959567546844\n",
            "tensor([[ 0.6739, -0.6492,  0.0869,  ..., -0.7574, -0.3958,  1.0114],\n",
            "        [-0.3578,  1.9019,  0.1936,  ...,  0.2286,  1.1161, -0.7882],\n",
            "        [-0.5533,  1.3922,  1.2111,  ..., -0.2498, -0.2558, -1.1688],\n",
            "        ...,\n",
            "        [-2.7835, -1.0857,  0.5521,  ..., -1.0286,  2.4490,  1.5231],\n",
            "        [ 1.6476, -0.5850,  0.4251,  ..., -0.1676, -1.3815,  0.6362],\n",
            "        [ 1.7578, -0.7610, -0.1666,  ...,  0.1843, -1.8085,  0.0121]],\n",
            "       grad_fn=<AddBackward0>) torch.Size([2708, 16])\n",
            "Graph(num_nodes=2708, num_edges=9501,\n",
            "      ndata_schemes={}\n",
            "      edata_schemes={})\n",
            "Graph(num_nodes=2708, num_edges=9501,\n",
            "      ndata_schemes={}\n",
            "      edata_schemes={})\n",
            "tensor([12.0045, 25.7889,  6.4768,  ..., 10.0317,  3.6405,  5.4525],\n",
            "       grad_fn=<SelectBackward0>) torch.Size([9501])\n",
            "tensor([-0.9854,  2.6498, -6.7362,  ..., -1.2919, -0.5400,  0.1985],\n",
            "       grad_fn=<SelectBackward0>) torch.Size([9501])\n",
            "tensor(0.1569, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) torch.Size([])\n",
            "AUC 0.843426697513533\n"
          ]
        }
      ],
      "source": [
        "# ----------- 3. set up loss and optimizer -------------- #\n",
        "# in this case, loss will in training loop\n",
        "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
        "#Initializes an Adam optimizer for training the model. It optimizes both the model's parameters (model.parameters()) and\n",
        "# the parameters of a predictor (pred.parameters()) using a learning rate of 0.01\n",
        "\n",
        "# ----------- 4. training -------------------------------- #\n",
        "all_logits = []\n",
        "for e in range(100):\n",
        "    # forward\n",
        "    h = model(train_g, train_g.ndata['feat'])\n",
        "    pos_score = pred(train_pos_g, h)\n",
        "    neg_score = pred(train_neg_g, h)\n",
        "    loss = compute_loss(pos_score, neg_score)\n",
        "    if(e == 99):\n",
        "      print(h,h.shape)\n",
        "      print(train_pos_g)\n",
        "      print(train_neg_g)\n",
        "      print(pos_score,pos_score.shape)\n",
        "      print(neg_score,neg_score.shape)\n",
        "      print(loss,loss.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if e % 5 == 0:\n",
        "        print('In epoch {}, loss: {}'.format(e, loss))\n",
        "\n",
        "# ----------- 5. check results ------------------------ #\n",
        "from sklearn.metrics import roc_auc_score\n",
        "with torch.no_grad():\n",
        "    pos_score = pred(test_pos_g, h)\n",
        "    neg_score = pred(test_neg_g, h)\n",
        "    print('AUC', compute_auc(pos_score, neg_score))\n",
        "\n",
        "\n",
        "# Thumbnail credits: Link Prediction with Neo4j, Mark Needham\n",
        "# sphinx_gallery_thumbnail_path = '_static/blitz_4_link_predict.png'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "https://docs.dgl.ai/en/0.8.x/tutorials/blitz/4_link_predict.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "ALay5QXvP5iN",
        "outputId": "af41830d-0f3f-4dfc-d027-5f9dcff22370"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-39-721e48fc1397>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    https://docs.dgl.ai/en/0.8.x/tutorials/blitz/4_link_predict.html\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}