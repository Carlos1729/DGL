{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carlos1729/DGL/blob/main/gnn_node_classification_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install watermark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hdHf5CV5WVh",
        "outputId": "a916bcf4-43bf-4369-8356-241d395cf17d"
      },
      "id": "4hdHf5CV5WVh",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: watermark in /usr/local/lib/python3.10/dist-packages (2.4.3)\n",
            "Requirement already satisfied: ipython>=6.0 in /usr/local/lib/python3.10/dist-packages (from watermark) (7.34.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from watermark) (6.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from watermark) (67.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->watermark) (3.17.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.0->watermark) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.0->watermark) (0.2.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  dgl -f https://data.dgl.ai/wheels/cu116/repo.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxNwkN3D5do4",
        "outputId": "a51ac366-0212-4637-c467-c723515a0e50"
      },
      "id": "BxNwkN3D5do4",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/cu116/repo.html\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (1.1.2+cu116)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.3)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wlnj5iBJ5dr1",
        "outputId": "4b1ca222-3b1f-4f7d-b7c1-7e4c263633c2"
      },
      "id": "Wlnj5iBJ5dr1",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
            "Requirement already satisfied: dglgo in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.9.0)\n",
            "Requirement already satisfied: isort>=5.10.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (5.12.0)\n",
            "Requirement already satisfied: autopep8>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (2.0.4)\n",
            "Requirement already satisfied: numpydoc>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.6.0)\n",
            "Requirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.10.13)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.20 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.18.5)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (6.0.1)\n",
            "Requirement already satisfied: ogb>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.3.6)\n",
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.10/dist-packages (from dglgo) (2022.9.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.2.2)\n",
            "Requirement already satisfied: pycodestyle>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.11.1)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: sphinx>=5 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (5.0.2)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (0.9.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (4.66.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.0.7)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (0.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (4.5.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.20->dglgo) (0.2.8)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.2.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.0->dglgo) (8.1.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi->dglgo) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (67.7.2)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (0.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2023.3.post1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.1.9)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.6)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.16.1)\n",
            "Requirement already satisfied: docutils<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (0.18.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.13.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics==0.11.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldvbnRyr5dva",
        "outputId": "9019f709-5e3b-4f22-cc47-6f42a6424888"
      },
      "id": "ldvbnRyr5dva",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics==0.11.4 in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.11.4) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.11.4) (2.1.0+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.11.4) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics==0.11.4) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics==0.11.4) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics==0.11.4) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3OJ5SDA6NHf",
        "outputId": "a1a78a19-50e9-43ba-a0da-680b51fe98d3"
      },
      "id": "r3OJ5SDA6NHf",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.11.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (2.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12.0->pytorch-lightning) (2.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->pytorch-lightning) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ee8c3be4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee8c3be4",
        "outputId": "d94de71e-3bd0-48ac-beeb-31ec7260cace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Ethen\n",
            "\n",
            "Last updated: 2023-11-06\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "dgl         : 1.1.2+cu116\n",
            "torch       : 2.1.0+cu118\n",
            "torchmetrics: 0.11.4\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. magic to print version\n",
        "# 2. magic so that the notebook will reload external python modules\n",
        "%load_ext watermark\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import dgl\n",
        "import torch\n",
        "import dgl.data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchmetrics.functional as MF\n",
        "from time import perf_counter\n",
        "from torchmetrics import Accuracy\n",
        "from ogb.nodeproppred import DglNodePropPredDataset\n",
        "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "%watermark -a \"Ethen\" -d -u -v -iv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2880089",
      "metadata": {
        "id": "d2880089"
      },
      "source": [
        "# Graph Neural Networks Node Classification Quick Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d5c6985",
      "metadata": {
        "id": "7d5c6985"
      },
      "source": [
        "In this particular notebook, we'll be:\n",
        "\n",
        "- Giving a quick introduction to Graph Neural Network.\n",
        "- Implement one particular algorithm GraphSAGE using [DGL](https://www.dgl.ai/), deep graph library. We'll be introducing how to work with DGL library on the graph node classification task.\n",
        "- Use Pytorch Lightning for organizing our building blocks and training our model. This isn't a PyTorch lightning tutorial, readers are expected to understand its concept such as `LightningDataModule`, `LightningModule` as well as `Trainer`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "701bc462",
      "metadata": {
        "id": "701bc462"
      },
      "source": [
        "A graph $\\mathcal{G}(V, E)$ is a data structure containing a set of nodes (a.k.a vertices) $i \\in V$ and a set of edges $e_{ij} \\in E$ connecting vertices $i$ and $j$. Each node $i$ has an associated node features $x_i \\in \\mathbb{R}^d$ and labels $y_i$\n",
        "\n",
        "A single Graph neural network (GNN) layer has three main steps that are performed on every node in the graph.\n",
        "\n",
        "1. Message Passing\n",
        "2. Aggregation\n",
        "3. Update\n",
        "\n",
        "**Message Passing:**\n",
        "\n",
        "GNN learns a node $i$ by examining nodes in its neighborhood $N_i$, where $N_i$ is defined as the set of nodes $j$ connected to the source node $i$ by an edge, more formally, $N_i = {j : e_{ij} \\in E}$. When examining a node, we can use any arbitrary function, $F$, either a neural network like, MLP, or here, let's assume it will be a affine transformation:\n",
        "\n",
        "\\begin{align}\n",
        "\\begin{aligned}\n",
        "F(x_j) = \\mathbf{W}_j \\cdot x_j + b\n",
        "\\end{aligned}\n",
        "\\end{align}\n",
        "\n",
        "Here, $\\cdot$ represents matrix multiplication.\n",
        "\n",
        "**Aggregation:**\n",
        "\n",
        "Now that we have the messages from neighborhood node, we have to aggregate them somehow. Popular aggregation function includes sum/mean/max/min. The aggregation function, $G$, can be denoted as:\n",
        "\n",
        "\\begin{align}\n",
        "\\begin{aligned}\n",
        "\\bar{m}_i = G(\\{F(x_j) : j \\in \\mathcal{N}_i\\})\n",
        "\\end{aligned}\n",
        "\\end{align}\n",
        "\n",
        "**Update:**\n",
        "\n",
        "The GNN layer now has to update our source node $i$'s features and combine it with the incoming aggregated messages. For example, using addition.\n",
        "\n",
        "\\begin{align}\n",
        "\\begin{aligned}\n",
        "h_i = \\sigma(K(T(x_i) + \\bar{m}_i)))\n",
        "\\end{aligned}\n",
        "\\end{align}\n",
        "\n",
        "Here, $T$, denotes a function that's applied to the source node $i$'s feature, $K$ denotes another transformation to project the blended features into another dimension, $\\sigma$ denotes an activation function such as Relu. Notation-wise, the initial node features are called $x_i$, after a forward pass through a GNN layer, we denote the node features as $h_i$. If we were to have multiple GNN layers, then we denote node features as $h_i^l$, where $l$ is the current GNN layer index.\n",
        "\n",
        "Note:\n",
        "\n",
        "- GNN aims to learn a function that generates embeddings via sampling and aggregation features from nodes' neighborhood. Innovations in GNN mainly involves changings to these three steps.\n",
        "- Number of layers in GNN is a hyperparameter that can be tweaked, the intuition is that $l^{th}$ GNN layer aggregate features from the $l^{th}$ hop neighborhood of node $i$. i.e. initially, the node sees its immediate neighbors and deeper into the network, it interacts with neighbors' neighbors and so on. Most GNN papers uses less than 4 layers to prevent the network from dying, where node embeddings all converge to similar representation after seeing nodes many hops away. This phenomenon becomes more prevalent for small and sparse graphs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28267c36",
      "metadata": {
        "id": "28267c36"
      },
      "source": [
        "## Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d344dcfa",
      "metadata": {
        "id": "d344dcfa"
      },
      "source": [
        "This code is largely ported from [DGL's Pytorch lightning node classification example](https://github.com/dmlc/dgl/blob/master/examples/pytorch/graphsage/lightning/node_classification.py) with additional explanations in between each section.\n",
        "\n",
        "We will be using the [ogbn-products](https://ogb.stanford.edu/docs/nodeprop/#ogbn-products) dataset. Directly copying this dataset's description from its description page.\n",
        "\n",
        "> ogbn-products dataset is an undirected and unweighted graph, representing an Amazon product co-purchasing network. Nodes represent products sold in Amazon, and edges between two products indicate that the products are purchased together. Node features are generated by extracting bag-of-words features from the product descriptions followed by a Principal Component Analysis to reduce the dimension to 100.\n",
        ">\n",
        "> The task is to predict the category of a product in a multi-class classification setup, where the 47 top-level categories are used for target labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "51a15271",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51a15271",
        "outputId": "1cf2ef79-9a1d-4aee-e03b-3d5e9837c7a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.08 GB: 100%|██████████| 81/81 [00:01<00:00, 68.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/arxiv.zip\n",
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1949.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting graphs into DGL objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes=169343, num_edges=1166243,\n",
              "      ndata_schemes={'year': Scheme(shape=(1,), dtype=torch.int64), 'feat': Scheme(shape=(128,), dtype=torch.float32)}\n",
              "      edata_schemes={})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dataset = DglNodePropPredDataset(\"ogbn-arxiv\")\n",
        "graph, labels = dataset[0]\n",
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "574492ca",
      "metadata": {
        "id": "574492ca"
      },
      "source": [
        "For DGL graph, we can assign or extract node's features via our graph's `ndata` attribute. Here, we assign dataset's label to our graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "eb874c56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb874c56",
        "outputId": "706bad0b-3570-4e99-e6ad-af62943d490d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'year': tensor([[2013],\n",
              "        [2015],\n",
              "        [2014],\n",
              "        ...,\n",
              "        [2020],\n",
              "        [2020],\n",
              "        [2020]]), 'feat': tensor([[-0.0579, -0.0525, -0.0726,  ...,  0.1734, -0.1728, -0.1401],\n",
              "        [-0.1245, -0.0707, -0.3252,  ...,  0.0685, -0.3721, -0.3010],\n",
              "        [-0.0802, -0.0233, -0.1838,  ...,  0.1099,  0.1176, -0.1399],\n",
              "        ...,\n",
              "        [-0.2205, -0.0366, -0.4022,  ...,  0.1134, -0.1614, -0.1452],\n",
              "        [-0.1382,  0.0409, -0.2518,  ..., -0.0893, -0.0413, -0.3761],\n",
              "        [-0.0299,  0.2684, -0.1611,  ...,  0.1208,  0.0776, -0.0910]]), 'label': tensor([ 4,  5, 28,  ..., 10,  4,  1])}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "graph.ndata[\"label\"] = labels.squeeze()\n",
        "graph.ndata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f54423e6",
      "metadata": {
        "id": "f54423e6"
      },
      "outputs": [],
      "source": [
        "# extract the train, validation and test split provided via the dataset\n",
        "split_idx = dataset.get_idx_split()\n",
        "train_idx, val_idx, test_idx = (\n",
        "    split_idx[\"train\"],\n",
        "    split_idx[\"valid\"],\n",
        "    split_idx[\"test\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5618a146",
      "metadata": {
        "id": "5618a146"
      },
      "source": [
        "### Data Module"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb939dfa",
      "metadata": {
        "id": "cb939dfa"
      },
      "source": [
        "Given a graph as well as data splits, we can get our hands dirty and implement our data module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "805c6efe",
      "metadata": {
        "id": "805c6efe"
      },
      "outputs": [],
      "source": [
        "class DataModule(LightningDataModule):\n",
        "\n",
        "    def __init__(\n",
        "        self, graph, train_idx, val_idx, fanouts, batch_size, n_classes, device\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        sampler = dgl.dataloading.NeighborSampler(\n",
        "            fanouts, prefetch_node_feats=[\"feat\"], prefetch_labels=[\"label\"]\n",
        "        )\n",
        "\n",
        "        self.graph = graph\n",
        "        self.train_idx = train_idx\n",
        "        self.val_idx = val_idx\n",
        "        self.sampler = sampler\n",
        "        self.batch_size = batch_size\n",
        "        self.in_feats = graph.ndata[\"feat\"].shape[1]\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return dgl.dataloading.DataLoader(\n",
        "            self.graph,\n",
        "            self.train_idx.to(device),\n",
        "            self.sampler,\n",
        "            device=device,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            drop_last=False,\n",
        "            num_workers=0,\n",
        "            use_uva=True\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return dgl.dataloading.DataLoader(\n",
        "            self.graph,\n",
        "            self.val_idx.to(device),\n",
        "            self.sampler,\n",
        "            device=device,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            drop_last=False,\n",
        "            num_workers=0,\n",
        "            use_uva=True,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3372c289",
      "metadata": {
        "id": "3372c289"
      },
      "source": [
        "Similar to general neural networks, we need a `DataLoader` to sample batches of inputs. A data loader by default returns 3 elements: `input_nodes`, `output_nodes`, `blocks`.\n",
        "\n",
        "`input_nodes` describe the nodes needed to compute the representation of `output_nodes`. Whereas `blocks` describe for each GNN layer, which node representations are to be computed as output, which node representations are needed as input, and how does representation from the input nodes propagate to the output nodes.\n",
        "\n",
        "Each data loader also accepts an sampler, here we are using one called `NeighborSampler`, which will make every node gather mesages from a fixed number of neighbors. We get to define the `fanouts` parameter for the sampler which represents number of neighbors to sample for each GNN layer.\n",
        "\n",
        "It also supports PyTorch concepts such as prefetching so model computation and data movement can happen in parallel, as well as a concept called [UVA (unified virtual addressing)](https://docs.dgl.ai/en/0.8.x/guide/minibatch-gpu-sampling.html#using-cuda-uva-based-neighborhood-sampling-in-dgl-data-loaders), directly quoting from its documentation: This is when our graph is too large to fit onto GPU memory, and we let GPU perform sampling on graph that will be pinned on CPU memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f68b591f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f68b591f",
        "outputId": "b8bab086-077a-4a67-b104-65fe52f11bfa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 56156,  49285, 138038,  46672,  91520, 100896,  66067, 154977, 131242,\n",
              "          22766,  90421, 115890, 138126,  68123, 141809,  49587,  57807,   9510,\n",
              "         168612,  27209], device='cuda:0'),\n",
              " tensor([56156, 49285], device='cuda:0'),\n",
              " [Block(num_src_nodes=20, num_dst_nodes=18, num_edges=67),\n",
              "  Block(num_src_nodes=18, num_dst_nodes=7, num_edges=36),\n",
              "  Block(num_src_nodes=7, num_dst_nodes=2, num_edges=5)])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "fanouts = [15, 10, 5]\n",
        "batch_size = 2\n",
        "data_module = DataModule(graph, train_idx, val_idx, fanouts, batch_size, dataset.num_classes, device)\n",
        "\n",
        "# sample output from the data loader\n",
        "input_nodes, output_nodes, blocks = next(iter(data_module.train_dataloader()))\n",
        "input_nodes, output_nodes, blocks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "840b3000",
      "metadata": {
        "id": "840b3000"
      },
      "source": [
        "### GraphSAGE Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25e2d4cb",
      "metadata": {
        "id": "25e2d4cb"
      },
      "source": [
        "[GraphSAGE](https://arxiv.org/abs/1706.02216) stands for Graph SAmple and AggreGatE, its forward pass can be described with the following notation:\n",
        "\n",
        "\\begin{align}\n",
        "\\begin{aligned}\n",
        "h_{N_i}^{(l+1)} &= \\mathrm{aggregate}^{(l+1)}\n",
        "\\left(\\{h_{j}^{l}, \\forall j \\in N_i \\}\\right)\\\\h_{i}^{(l+1)} &= \\sigma \\left(W^{(l+1)} \\cdot \\mathrm{concat}\n",
        "(h_{i}^{l}, h_{N_i}^{l+1}) \\right)\\\\h_{i}^{(l+1)} &= \\mathrm{norm}(h_{i}^{(l+1)})\n",
        "\\end{aligned}\n",
        "\\end{align}\n",
        "\n",
        "Hopefully each of these steps won't look that alien after covering the general pattern of GNN.\n",
        "\n",
        "- For each node, it aggregates feature representation from its immediate neighborhood, which can be uniformly sampled. The original paper uses aggregation function such as mean, pooling, LSTM.\n",
        "- After aggregating neighboring feature representations, it then concatenates it with the node's current representation. This concatenation is then fed through a fully connected layer with nonlinear activation function.\n",
        "- The last step is normalizing learned embedding to unit length."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f09dd873",
      "metadata": {
        "id": "f09dd873"
      },
      "source": [
        "The way this works in DGL is if our features are stored in a graph object's `ndata`, then from a sampled block object we can access source nodes' feature via `srcdata` and destination nodes' feature via `dstdata`. In the next few code chunks, we first perform a small demo where we access source node's features, feed it through a GNN layer, and check whether its shape matches output nodes' label size. After that we'll proceed with implementing our main model/module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c650d21a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c650d21a",
        "outputId": "9801ee96-97c2-4cee-ec03-a96d6193b04f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "blocks[0].srcdata[\"feat\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b99b2694",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b99b2694",
        "outputId": "4622d3c7-6a9c-4db5-f5c2-75a44f31eb0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# out_feats is configurable, analogous to hidden layer's dimension size\n",
        "sage_conv = dgl.nn.SAGEConv(\n",
        "    in_feats=data_module.in_feats,\n",
        "    out_feats=256,\n",
        "    aggregator_type=\"mean\"\n",
        ").to(device)\n",
        "output = sage_conv(blocks[0], blocks[0].srcdata[\"feat\"])\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bd0f0399",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd0f0399",
        "outputId": "1e72ebd6-29c4-4bcf-ec7b-568966a5a4bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "blocks[0].dstdata[\"label\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trqh_lVM93oT",
        "outputId": "a5d2cf47-54a0-4db4-db83-61dc048e5b40"
      },
      "id": "trqh_lVM93oT",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.11.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (2.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12.0->pytorch-lightning) (2.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->pytorch-lightning) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "fd1db1e7",
      "metadata": {
        "id": "fd1db1e7"
      },
      "outputs": [],
      "source": [
        "class SAGE(LightningModule):\n",
        "    \"\"\"Multi-layer GraphSAGE lightning module for node classification task.\"\"\"\n",
        "\n",
        "    def __init__(self, in_feats: int, n_layers: int, n_hidden: int, n_classes: int, aggregator_type: str):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(dgl.nn.SAGEConv(in_feats, n_hidden, aggregator_type))\n",
        "        for i in range(1, n_layers - 1):\n",
        "            self.layers.append(dgl.nn.SAGEConv(n_hidden, n_hidden, aggregator_type))\n",
        "\n",
        "        self.layers.append(dgl.nn.SAGEConv(n_hidden, n_classes, aggregator_type))\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_classes = n_classes\n",
        "        self.train_acc = Accuracy(task='multiclass', num_classes=n_classes)\n",
        "        self.val_acc = Accuracy(task='multiclass', num_classes=n_classes)\n",
        "\n",
        "    def forward(self, blocks, x):\n",
        "        h = x\n",
        "        for l, (layer, block) in enumerate(zip(self.layers, blocks)):\n",
        "            h = layer(block, h)\n",
        "            if l != len(self.layers) - 1:\n",
        "                h = F.relu(h)\n",
        "                h = self.dropout(h)\n",
        "        return h\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_nodes, output_nodes, blocks = batch\n",
        "        x = blocks[0].srcdata[\"feat\"]\n",
        "        y = blocks[-1].dstdata[\"label\"]\n",
        "        y_hat = self(blocks, x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        self.train_acc(torch.argmax(y_hat, 1), y)\n",
        "        self.log(\n",
        "            \"train_acc\",\n",
        "            self.train_acc,\n",
        "            prog_bar=True,\n",
        "            on_step=True,\n",
        "            on_epoch=False\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input_nodes, output_nodes, blocks = batch\n",
        "        x = blocks[0].srcdata[\"feat\"]\n",
        "        y = blocks[-1].dstdata[\"label\"]\n",
        "        y_hat = self(blocks, x)\n",
        "        self.val_acc(torch.argmax(y_hat, 1), y)\n",
        "        self.log(\n",
        "            \"val_acc\",\n",
        "            self.val_acc,\n",
        "            prog_bar=True,\n",
        "            on_step=True,\n",
        "            on_epoch=True,\n",
        "            sync_dist=True\n",
        "        )\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(\n",
        "            self.parameters(),\n",
        "            lr=0.001,\n",
        "            weight_decay=5e-4\n",
        "        )\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9dafc88b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dafc88b",
        "outputId": "291fe5db-a0a3-4d29-89e7-5db0a41f7440"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SAGE(\n",
              "  (layers): ModuleList(\n",
              "    (0): SAGEConv(\n",
              "      (feat_drop): Dropout(p=0.0, inplace=False)\n",
              "      (fc_neigh): Linear(in_features=128, out_features=256, bias=False)\n",
              "      (fc_self): Linear(in_features=128, out_features=256, bias=True)\n",
              "    )\n",
              "    (1): SAGEConv(\n",
              "      (feat_drop): Dropout(p=0.0, inplace=False)\n",
              "      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)\n",
              "      (fc_self): Linear(in_features=256, out_features=256, bias=True)\n",
              "    )\n",
              "    (2): SAGEConv(\n",
              "      (feat_drop): Dropout(p=0.0, inplace=False)\n",
              "      (fc_neigh): Linear(in_features=256, out_features=40, bias=False)\n",
              "      (fc_self): Linear(in_features=256, out_features=40, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (train_acc): MulticlassAccuracy()\n",
              "  (val_acc): MulticlassAccuracy()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model = SAGE(\n",
        "    in_feats=data_module.in_feats,\n",
        "    n_layers=len(fanouts),\n",
        "    n_hidden=256,\n",
        "    n_classes=data_module.n_classes,\n",
        "    aggregator_type=\"mean\"\n",
        ")\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e6a0626",
      "metadata": {
        "id": "3e6a0626"
      },
      "source": [
        "### Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d901d0b2",
      "metadata": {
        "id": "d901d0b2"
      },
      "source": [
        "The node chunk initiatizes the data as well as model module and kicks off model training through Trainer class ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5fe18066",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fe18066",
        "outputId": "f569951a-6eee-4941-8967-0e2b91acbd1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name      | Type               | Params\n",
            "-------------------------------------------------\n",
            "0 | layers    | ModuleList         | 217 K \n",
            "1 | dropout   | Dropout            | 0     \n",
            "2 | train_acc | MulticlassAccuracy | 0     \n",
            "3 | val_acc   | MulticlassAccuracy | 0     \n",
            "-------------------------------------------------\n",
            "217 K     Trainable params\n",
            "0         Non-trainable params\n",
            "217 K     Total params\n",
            "0.871     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:121: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (89) is smaller than the logging interval Trainer(log_every_n_steps=100). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 35.69494626000005\n"
          ]
        }
      ],
      "source": [
        "n_hidden = 256\n",
        "fanouts = [15, 10, 5]\n",
        "aggregator_type = \"mean\"\n",
        "batch_size = 1024\n",
        "n_layers = len(fanouts)\n",
        "\n",
        "data_module = DataModule(graph, train_idx, val_idx, fanouts, batch_size, dataset.num_classes, device)\n",
        "model = SAGE(\n",
        "    in_feats=data_module.in_feats,\n",
        "    n_layers=n_layers,\n",
        "    n_hidden=n_hidden,\n",
        "    n_classes=data_module.n_classes,\n",
        "    aggregator_type=aggregator_type\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(monitor=\"val_acc\", save_top_k=1)\n",
        "trainer = Trainer(\n",
        "    accelerator='gpu',\n",
        "    devices=[0],\n",
        "    max_epochs=10,\n",
        "    # note, we purpose-fully disabled the progress bar to prevent flooding our notebook's console\n",
        "    # in normal settings, we can/should definitely turn it on\n",
        "    enable_progress_bar=False,\n",
        "    log_every_n_steps=100,\n",
        "    callbacks=[checkpoint_callback]\n",
        ")\n",
        "t1_start = perf_counter()\n",
        "trainer.fit(model, datamodule=data_module)\n",
        "t1_stop = perf_counter()\n",
        "print(\"Elapsed time:\", t1_stop - t1_start)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a023a443",
      "metadata": {
        "id": "a023a443"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2747740b",
      "metadata": {
        "id": "2747740b"
      },
      "source": [
        "The prediction/evaluation is also a bit interesting. As explained clearly by [DGL Tutorial - Exact Offline Inference on Large Graphs](https://docs.dgl.ai/en/0.8.x/guide/minibatch-inference.html) While training our GNN, we often times perform neighborhood sampling for reducing memory. But while performing inferencing, it's better to truly aggregate over all neighbors.\n",
        "\n",
        "The result of this is that our inference implemention will be slightly different compared to training. During training, we have an outer loop that's iterating over mini-batches of nodes (this is coming from our DataLoader), and an inner loop that's iterating over all our GNN's layer. During inferencing, what will happen is, we instead will have an outer loop that's iterating over the GNN layers, and an inner loop that's iterating over our mini-batches of nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ca5d7362",
      "metadata": {
        "id": "ca5d7362"
      },
      "outputs": [],
      "source": [
        "def predict(graph, model, batch_size, device):\n",
        "    graph.ndata[\"h\"] = graph.ndata[\"feat\"]\n",
        "    sampler = dgl.dataloading.MultiLayerFullNeighborSampler(1)\n",
        "    data_loader = dgl.dataloading.DataLoader(\n",
        "        graph,\n",
        "        torch.arange(graph.number_of_nodes()).to(device),\n",
        "        sampler,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        drop_last=False,\n",
        "        device=device,\n",
        "        num_workers=0,\n",
        "        use_uva=True\n",
        "    )\n",
        "\n",
        "    for l, layer in enumerate(model.layers):\n",
        "        y = torch.zeros(\n",
        "            graph.num_nodes(),\n",
        "            model.n_hidden if l != len(model.layers) - 1 else model.n_classes,\n",
        "            device='cpu'\n",
        "        )\n",
        "        for input_nodes, output_nodes, blocks in data_loader:\n",
        "            block = blocks[0]\n",
        "            x = block.srcdata['h']\n",
        "            h = layer(block, x)\n",
        "            if l != len(model.layers) - 1:\n",
        "                h = F.relu(h)\n",
        "                h = model.dropout(h)\n",
        "\n",
        "            y[output_nodes] = h.to('cpu')\n",
        "\n",
        "        graph.ndata[\"h\"] = y\n",
        "\n",
        "    del graph.ndata['h']\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "8b8b58a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "8b8b58a7",
        "outputId": "315b8221-b565-4c72-a0d2-933488e766e8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2b84e4598fbe>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchmetrics/functional/classification/accuracy.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(preds, target, task, threshold, num_classes, num_labels, average, multidim_average, top_k, ignore_index, validate_args)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultidim_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         return multiclass_accuracy(\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "predict_batch_size = 4096\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred = predict(graph, model.to(device), predict_batch_size, device)\n",
        "    pred = pred[test_idx]\n",
        "    label = graph.ndata[\"label\"][test_idx]\n",
        "    accuracy = MF.accuracy(pred, label,task='multiclass')\n",
        "    accuracy = round(accuracy.item(), 3)\n",
        "\n",
        "print(\"Test accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fa141ca",
      "metadata": {
        "id": "6fa141ca"
      },
      "source": [
        "Hopefully, this served as a quick introduction to GNN's node classification task. Feel free to check the [leaderboard](https://ogb.stanford.edu/docs/leader_nodeprop/#ogbn-products) for potential improvements to this baseline approach."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20347f10",
      "metadata": {
        "id": "20347f10"
      },
      "source": [
        "## Reference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43155425",
      "metadata": {
        "id": "43155425"
      },
      "source": [
        "- [Blog: Math Behind Graph Neural Networks](https://rish-16.github.io/posts/gnn-math/)\n",
        "- [DGL Tutorial - Training GNN for Node Classification with Neighborhood Sampling](https://docs.dgl.ai/en/0.8.x/guide/minibatch-node.html#guide-minibatch-node-classification-sampler)\n",
        "- [DGL Tutorial - Exact Offline Inference on Large Graphs](https://docs.dgl.ai/en/0.8.x/guide/minibatch-inference.html)\n",
        "- [Paper - William L. Hamilton, Rex Ying, Jure Leskovec : Inductive Representation Learning on Large Graphs (2017)](https://arxiv.org/abs/1706.02216)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "toc-showtags": false,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}